{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdzRVTmL__6O",
        "outputId": "adf44312-c2c5-4681-d565-be9dd0c65312"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the number of data points (N): 6\n",
            "Enter the number of features (M): 5\n",
            "Enter the number of RBM layers (L): 2\n",
            "\n",
            "Enter the binary data matrix of size 6 x 5:\n",
            "Row 1: 1 0 1 1 0\n",
            "Row 2: 0 1 0 1 1\n",
            "Row 3: 1 1 1 0 0\n",
            "Row 4: 0 0 1 1 1\n",
            "Row 5: 1 0 0 1 1\n",
            "Row 6: 0 1 1 0 0 \n",
            "\n",
            "Training Layer 1...\n",
            "  Best Feature Subset: [0, 2, 4]\n",
            "  Reconstruction Loss: 0.2565282345893219\n",
            "  Optimal Hidden Units: 3\n",
            "  Final Reconstruction Loss: 0.2565282345893219\n",
            "\n",
            "Training Layer 2...\n",
            "  Best Feature Subset: [0, 1, 2]\n",
            "  Reconstruction Loss: 0.0004402580140816877\n",
            "  Optimal Hidden Units: 3\n",
            "  Final Reconstruction Loss: 0.0004402580140816877\n",
            "\n",
            "Final Results:\n",
            "Inputs:\n",
            "N: 6, M: 5, L: 2\n",
            "Data (N x M):\n",
            "[[1 0 1 1 0]\n",
            " [0 1 0 1 1]\n",
            " [1 1 1 0 0]\n",
            " [0 0 1 1 1]\n",
            " [1 0 0 1 1]\n",
            " [0 1 1 0 0]]\n",
            "\n",
            "Outputs:\n",
            "Layer 1:\n",
            "  Subset of Features: [0, 2, 4]\n",
            "  Number of Hidden Units: 3\n",
            "Layer 2:\n",
            "  Subset of Features: [0, 1, 2]\n",
            "  Number of Hidden Units: 3\n"
          ]
        }
      ],
      "source": [
        "# Name:Yatharth\n",
        "import numpy as np\n",
        "from sklearn.neural_network import BernoulliRBM\n",
        "from itertools import combinations\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def greedy_rbm_training(data, num_layers):\n",
        "    # Initialize variables\n",
        "    num_data, num_features = data.shape\n",
        "    trained_layers = []  # To store feature subsets and hidden units for each layer\n",
        "    input_data = data    # Start with the original data as input for the first layer\n",
        "    original_features = list(range(num_features))  # Track original feature indices\n",
        "\n",
        "    for layer in range(1, num_layers + 1):\n",
        "        print(f\"\\nTraining Layer {layer}...\")\n",
        "\n",
        "        # Step 1: Find the best subset of features for the current layer\n",
        "        best_features = None\n",
        "        best_reconstruction_loss = float('inf')\n",
        "        subset_size = min(3, len(original_features))  # Adjust subset size to remaining features\n",
        "\n",
        "        for feature_subset in combinations(original_features, subset_size):\n",
        "            feature_subset = list(feature_subset)\n",
        "\n",
        "            # Train RBM on the feature subset\n",
        "            rbm = BernoulliRBM(n_components=3, random_state=42)  # Start with 3 hidden units\n",
        "            rbm.fit(input_data[:, feature_subset])\n",
        "\n",
        "            # Manually compute reconstruction\n",
        "            hidden_activations = rbm.transform(input_data[:, feature_subset])  # Hidden layer\n",
        "            reconstructed_data = (hidden_activations @ rbm.components_) + rbm.intercept_visible_\n",
        "            reconstructed_data = 1 / (1 + np.exp(-reconstructed_data))  # Sigmoid activation\n",
        "\n",
        "            # Compute reconstruction loss\n",
        "            reconstruction_loss = mean_squared_error(input_data[:, feature_subset], reconstructed_data)\n",
        "\n",
        "            if reconstruction_loss < best_reconstruction_loss:\n",
        "                best_reconstruction_loss = reconstruction_loss\n",
        "                best_features = feature_subset\n",
        "\n",
        "        print(f\"  Best Feature Subset: {best_features}\")\n",
        "        print(f\"  Reconstruction Loss: {best_reconstruction_loss}\")\n",
        "\n",
        "        # Step 2: Determine the optimal number of hidden units for the best feature subset\n",
        "        best_hidden_units = None\n",
        "        best_hidden_loss = float('inf')\n",
        "        hidden_unit_range = range(1, 6)  # Test hidden units from 1 to 5 (can be adjusted)\n",
        "\n",
        "        for n_hidden in hidden_unit_range:\n",
        "            rbm = BernoulliRBM(n_components=n_hidden, random_state=42)\n",
        "            rbm.fit(input_data[:, best_features])\n",
        "\n",
        "            # Manually compute reconstruction\n",
        "            hidden_activations = rbm.transform(input_data[:, best_features])  # Hidden layer\n",
        "            reconstructed_data = (hidden_activations @ rbm.components_) + rbm.intercept_visible_\n",
        "            reconstructed_data = 1 / (1 + np.exp(-reconstructed_data))  # Sigmoid activation\n",
        "\n",
        "            # Compute reconstruction loss\n",
        "            hidden_loss = mean_squared_error(input_data[:, best_features], reconstructed_data)\n",
        "\n",
        "            if hidden_loss < best_hidden_loss:\n",
        "                best_hidden_loss = hidden_loss\n",
        "                best_hidden_units = n_hidden\n",
        "\n",
        "        print(f\"  Optimal Hidden Units: {best_hidden_units}\")\n",
        "        print(f\"  Final Reconstruction Loss: {best_hidden_loss}\")\n",
        "\n",
        "        # Store the layer's results\n",
        "        trained_layers.append({\n",
        "            \"layer\": layer,\n",
        "            \"features\": best_features,\n",
        "            \"hidden_units\": best_hidden_units\n",
        "        })\n",
        "\n",
        "        # Transform the data for the next layer\n",
        "        rbm = BernoulliRBM(n_components=best_hidden_units, random_state=42)\n",
        "        rbm.fit(input_data[:, best_features])\n",
        "        input_data = rbm.transform(input_data[:, best_features])  # Hidden representations\n",
        "\n",
        "        # Update original features to reflect the new feature space\n",
        "        original_features = list(range(input_data.shape[1]))\n",
        "\n",
        "    return trained_layers\n",
        "\n",
        "# Collect user inputs\n",
        "N = int(input(\"Enter the number of data points (N): \"))\n",
        "M = int(input(\"Enter the number of features (M): \"))\n",
        "L = int(input(\"Enter the number of RBM layers (L): \"))\n",
        "\n",
        "# Validate constraints\n",
        "if not (1 <= N <= 1000 and 1 <= M <= 1000 and 1 <= L <= 1000):\n",
        "    raise ValueError(\"Constraints violated: 1 <= N, M, L <= 1000\")\n",
        "print(f\"\\nEnter the binary data matrix of size with space in each digit {N} x {M}:\")\n",
        "data = []\n",
        "for i in range(N):\n",
        "    row = list(map(int, input(f\"Row {i + 1}: \").strip().split()))\n",
        "    if len(row) != M or any(x not in [0, 1] for x in row):\n",
        "        raise ValueError(\"Each row must have M binary (0 or 1) values.\")\n",
        "    data.append(row)\n",
        "data = np.array(data)\n",
        "\n",
        "# Run the RBM training algorithm\n",
        "result = greedy_rbm_training(data, L)\n",
        "\n",
        "# Display the final results\n",
        "print(\"\\nFinal Results:\")\n",
        "print(f\"Inputs:\")\n",
        "print(f\"N: {N}, M: {M}, L: {L}\")\n",
        "print(f\"Data (N x M):\\n{data}\")\n",
        "print(\"\\nOutputs:\")\n",
        "for layer in result:\n",
        "    print(f\"Layer {layer['layer']}:\")\n",
        "    print(f\"  Subset of Features: {layer['features']}\")\n",
        "    print(f\"  Number of Hidden Units: {layer['hidden_units']}\")\n"
      ]
    }
  ]
}